import os
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity
from Chat_with_Datawhale_langchain.utils.call_embedding import get_embedding
from api_config import api_config


def delete_md_files(folder: str):
    count = 0
    for filename in os.listdir(folder):
        if filename.endswith(".md"):
            file_path = os.path.join(folder, filename)
            try:
                os.remove(file_path)
                print(f"å·²åˆ é™¤: {file_path}")
                count += 1
            except Exception as e:
                print(f"åˆ é™¤å¤±è´¥: {file_path}ï¼ŒåŸå› : {e}")
    print(f"âœ… å…±åˆ é™¤ {count} ä¸ª .md æ–‡ä»¶")


class InstructionDetector:
    def __init__(self, embeddings, texts: list[str], threshold: float = 0.75):
        self.embeddings = embeddings
        self.texts = texts
        self.threshold = threshold
        self.text_embs = self.embeddings.embed_documents(texts)
        self.dir_path = "chat_logs"

    def match(self, text: str) -> bool:
        text = text.strip()
        if not text:
            return False
        emb = self.embeddings.embed_query(text)
        sims = cosine_similarity([emb], self.text_embs)[0]
        max_sim = max(sims)
        print(f"[DEBUG] ç›¸ä¼¼åº¦ = {max_sim:.4f}")
        return max_sim >= self.threshold


class ChatSaver:
    def __init__(self, folder: str = "chat_logs"):
        self.folder = folder
        os.makedirs(folder, exist_ok=True)

    def save(self, chat_history: list[str]) -> str:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(self.folder, f"chat_history_{timestamp}.md")
        with open(filename, "w", encoding="utf-8") as f:
            for msg in chat_history:
                f.write(msg + "\n\n")
        print(f"âœ… èŠå¤©è®°å½•å·²ä¿å­˜è‡³: {filename}")
        return filename


class SemanticTool:
    def __init__(self, name, examples, handler, embeddings, threshold=0.75):
        self.name = name
        self.detector = InstructionDetector(embeddings, examples, threshold)
        self.handler = handler

    def try_handle(self, text: str):
        if self.detector.match(text):
            print(f"[DEBUG] è¯­ä¹‰åŒ¹é…è§¦å‘å·¥å…·ï¼š{self.name}")
            return self.handler(text)
        return None


class ToolRegistry:
    def __init__(self):
        self.tools: list[SemanticTool] = []

    def register_tool(self, tool: SemanticTool):
        self.tools.append(tool)

    def match_tool(self, text: str):
        for tool in self.tools:
            result = tool.try_handle(text)
            if result is not None:
                return result
        return None


class ChatSession:
    def __init__(self, embedding_model_name="tongyi"):
        self.embeddings = get_embedding(embedding_model_name, api_config.get_api_key())
        self.chat_history = []
        self.dir_path = "chat_logs"
        self.saver = ChatSaver(self.dir_path)
        self.tool_registry = ToolRegistry()
        self.register_semantic_tools()

    def add_user_message(self, msg: str):
        self.chat_history.append(f"ä½ ï¼š{msg}")

    def add_assistant_message(self, msg: str):
        self.chat_history.append(f"åŠ©æ‰‹ï¼š{msg}")

    def save_chat(self, *_):
        path = self.saver.save(self.chat_history)
        return f"âœ… èŠå¤©è®°å½•å·²ä¿å­˜è‡³ï¼š{path}"

    def clear_chat(self, *_):
        delete_md_files(self.dir_path)
        self.chat_history.clear()
        return "âœ… èŠå¤©è®°å½•å·²æ¸…ç©ºã€‚"

    def show_chat_history(self, *_):
        if not self.chat_history:
            return "ğŸ“­ å½“å‰æ— èŠå¤©è®°å½•ã€‚"
        return "ğŸ“ æœ€è¿‘èŠå¤©è®°å½•ï¼š\n" + "-" * 20 + "\n" + "\n".join(self.chat_history[-5:]) + "\n" + "-" * 20

    def register_semantic_tools(self):
        self.tool_registry.register_tool(SemanticTool(
            name="ä¿å­˜èŠå¤©",
            examples=[
                "ä¿å­˜å¯¹è¯", "è®°å½•èŠå¤©", "è¯·ä¿å­˜ä¸€ä¸‹", "å¸®æˆ‘å¤‡ä»½", "èƒ½ä¸èƒ½ä¿å­˜èŠå¤©è®°å½•", "æˆ‘æƒ³æŠŠèŠå¤©å†…å®¹ç•™ä¸‹æ¥"
            ],
            handler=self.save_chat,
            embeddings=self.embeddings
        ))
        self.tool_registry.register_tool(SemanticTool(
            name="æ¸…ç©ºèŠå¤©",
            examples=[
                "æ¸…ç©ºå¯¹è¯", "é‡ç½®èŠå¤©", "è¯·æ¸…é™¤æ‰€æœ‰è®°å½•", "æŠŠèŠå¤©å†…å®¹æ¸…ç©º", "é‡æ–°å¼€å§‹"
            ],
            handler=self.clear_chat,
            embeddings=self.embeddings
        ))
        self.tool_registry.register_tool(SemanticTool(
            name="æŸ¥çœ‹å†å²",
            examples=[
                "æŸ¥çœ‹èŠå¤©è®°å½•", "å±•ç¤ºæœ€è¿‘èŠå¤©", "èƒ½çœ‹åˆ°åˆšæ‰è¯´çš„å—", "çœ‹çœ‹ä¹‹å‰çš„èŠå¤©", "å›é¡¾ä¸€ä¸‹èŠå¤©å†…å®¹"
            ],
            handler=self.show_chat_history,
            embeddings=self.embeddings
        ))

    def default_reply(self, user_input: str) -> str:
        return "ï¼ˆæ¨¡æ‹Ÿå›å¤ï¼‰æˆ‘ç†è§£äº†ä½ çš„é—®é¢˜ã€‚"

    def process_input(self, user_input: str) -> str:
        user_input = user_input.strip()
        if not user_input:
            return ""

        self.add_user_message(user_input)

        # å°è¯•è¯­ä¹‰åŒ¹é…å·¥å…·
        tool_response = self.tool_registry.match_tool(user_input)
        if tool_response:
            self.add_assistant_message(tool_response)
            return tool_response

        # é»˜è®¤ LLM å›å¤
        reply = self.default_reply(user_input)
        self.add_assistant_message(reply)
        return reply

    def interactive_loop(self):
        print("ğŸ—¨ï¸ å¼€å§‹èŠå¤©ï¼ˆè¾“å…¥ç©ºè¡Œé€€å‡ºï¼‰")
        while True:
            user_input = input("ä½ ï¼š").strip()
            if not user_input:
                print("ğŸ‘‹ å†è§ï¼")
                break
            reply = self.process_input(user_input)
            print(f"åŠ©æ‰‹ï¼š{reply}")


if __name__ == "__main__":
    session = ChatSession()
    session.interactive_loop()
